{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from taucc.taucc import CoClust as CC\n",
    "from tautcc.tautcc import CoClust as TCC\n",
    "from dptaucc.dptaucc import CoClust as DPCC\n",
    "from sklearn.metrics import adjusted_rand_score as ARI \n",
    "from sklearn.metrics import normalized_mutual_info_score as NMI\n",
    "from coclust.coclustering import CoclustInfo as ITCC, CoclustSpecMod as SMCC, CoclustMod as MCC\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tracemalloc\n",
    "from sklearn.datasets import make_biclusters\n",
    "\n",
    "\n",
    "B, rlabel, clabel = make_biclusters(shape=(1000,1000), n_clusters=5, random_state=42, minval=10, maxval=100, shuffle=True)\n",
    "B= np.array(B.astype(int))\n",
    "row_labels = np.zeros(np.shape(B)[0])\n",
    "col_labels = np.zeros(np.shape(B)[1])\n",
    "rl = np.where(rlabel==True)\n",
    "row_labels[rl[1][:len(row_labels)]] = rl[0][:len(row_labels)]\n",
    "cl = np.where(clabel==True)\n",
    "col_labels[cl[1][:len(col_labels)]] = cl[0][:len(col_labels)]\n",
    "\n",
    "#model = DPCC(eps = 1, n_iterations = 3, n_iter_per_mode = 5, k = 5, l = 5, verbose = True)\n",
    "model = CC(k = 100, l = 100, verbose = True)\n",
    "#model = TCC(k=[100,100], verbose = True)\n",
    "tracemalloc.start()\n",
    "model.fit(B)\n",
    "_, mem = tracemalloc.get_traced_memory()\n",
    "print(f'used RAM: {mem/(1024*1024):0.2f}MB')\n",
    "print(ARI(row_labels,model.row_labels_))\n",
    "print(NMI(row_labels,model.row_labels_))\n",
    "print(ARI(col_labels,model.column_labels_))\n",
    "print(NMI(col_labels,model.column_labels_))\n",
    "#print(model.eps_used)\n",
    "tx, ty = model.compute_taus()\n",
    "t = model.compute_taus()\n",
    "#print(\"taux: \",str(t[0]))\n",
    "#print(\"tauy: \",str(t[1]))\n",
    "print(\"taux: \",str(tx))\n",
    "print(\"tauy: \",str(ty))\n",
    "print(model.execution_time_)\n",
    "tracemalloc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from taucc.taucc import CoClust as CC\n",
    "from tautcc.tautcc import CoClust as TCC\n",
    "from dptaucc.dptaucc import CoClust as DPCC\n",
    "from sklearn.metrics import adjusted_rand_score as ARI \n",
    "from sklearn.metrics import normalized_mutual_info_score as NMI\n",
    "from sklearn.datasets import make_biclusters\n",
    "from tautcc.CreateMatrix import CreateTensor3\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tracemalloc\n",
    "\n",
    "\n",
    "V, x, y, z = CreateTensor3(nrows = 1000, ncols = 1000, nz = 100, rowclust = 5, colclust = 5, zclust = 5, noise=0.15)\n",
    "\n",
    "model = TCC(k=[5,5,5], verbose=True)\n",
    "tracemalloc.start()\n",
    "model.fit(V)\n",
    "_, mem = tracemalloc.get_traced_memory()\n",
    "print(f'used RAM: {mem/(1024*1024):0.2f}MB')\n",
    "print(ARI(x,model.labels_[0]))\n",
    "print(ARI(y,model.labels_[1]))\n",
    "print(ARI(z,model.labels_[2]))\n",
    "print(model.execution_time_)\n",
    "tracemalloc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from taucc.taucc import CoClust as CC\n",
    "from tautcc.tautcc import CoClust as TCC\n",
    "from dptaucc.dptaucc import CoClust as DPCC\n",
    "from coclust.coclustering import CoclustInfo as ITCC, CoclustSpecMod as SMCC, CoclustMod as MCC\n",
    "from sklearn.metrics import adjusted_rand_score as ARI \n",
    "from sklearn.metrics import normalized_mutual_info_score as NMI\n",
    "from sklearn.datasets import make_biclusters\n",
    "from tautcc.CreateMatrix import CreateTensor3\n",
    "import numpy as np\n",
    "from time import time\n",
    "import pandas as pd\n",
    "import tracemalloc\n",
    "\n",
    "dt = pd.read_csv(f'../data/cstr.txt')\n",
    "t = pd.read_csv(f'../data/cstr_target.txt', header = None)\n",
    "target = np.array(t).T[0]\n",
    "\n",
    "\n",
    "n = len(dt.doc.unique())\n",
    "m = len(dt.word.unique())\n",
    "k = len(t[0].unique())\n",
    "T = np.zeros((n,m), dtype = int)\n",
    "\n",
    "\n",
    "for g in dt.iterrows():\n",
    "    T[g[1].doc,g[1].word] = g[1].cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ari1 = []\n",
    "nmi1 = []\n",
    "time1 = []\n",
    "\n",
    "for i in range(20):\n",
    "    print(i)\n",
    "    model = DPCC(eps = 1., n_iterations = 3, k = 5, l = 5, random_state=None, verbose = False)\n",
    "    model.fit(T)\n",
    "    ari1.append(ARI(target,model.row_labels_))\n",
    "    nmi1.append(NMI(target,model.row_labels_))\n",
    "    time1.append(model.execution_time_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ari2 = []\n",
    "nmi2 = []\n",
    "time2 = []\n",
    "\n",
    "for i in range(20):\n",
    "    print(i)\n",
    "    model = CC(k = 100, l = 100, initialization='random', verbose = False)\n",
    "    model.fit(T)\n",
    "    ari2.append(ARI(target,model.row_labels_))\n",
    "    nmi2.append(NMI(target,model.row_labels_))\n",
    "    time2.append(model.execution_time_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ari3 = []\n",
    "nmi3 = []\n",
    "time3 = []\n",
    "\n",
    "for i in range(20):\n",
    "    print(i)\n",
    "    model = ITCC(n_row_clusters=4, n_col_clusters=4)\n",
    "    start_time=time()\n",
    "    model.fit(T)\n",
    "    end_time=time()\n",
    "    ari3.append(ARI(target,model.row_labels_))\n",
    "    nmi3.append(NMI(target,model.row_labels_))\n",
    "    time3.append(end_time - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ari4 = []\n",
    "nmi4 = []\n",
    "time4 = []\n",
    "\n",
    "\n",
    "for i in range(20):\n",
    "    print(i)\n",
    "    model = MCC(n_clusters=4)\n",
    "    start_time=time()\n",
    "    model.fit(T)\n",
    "    end_time=time()\n",
    "    ari4.append(ARI(target,model.row_labels_))\n",
    "    nmi4.append(NMI(target,model.row_labels_))\n",
    "    time4.append(end_time - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ari5 = []\n",
    "nmi5 = []\n",
    "time5 = []\n",
    "\n",
    "\n",
    "for i in range(20):\n",
    "    print(i)\n",
    "    model = SMCC(n_clusters=4)\n",
    "    start_time=time()\n",
    "    model.fit(T)\n",
    "    end_time=time()\n",
    "    ari5.append(ARI(target,model.row_labels_))\n",
    "    nmi5.append(NMI(target,model.row_labels_))\n",
    "    time5.append(end_time - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.array(ari1).mean())\n",
    "print(np.array(ari1).std())\n",
    "print(np.array(nmi1).mean())\n",
    "print(np.array(nmi1).std())\n",
    "print(np.array(time1).mean())\n",
    "print(np.array(time1).std())\n",
    "print(\"===\")\n",
    "print(np.array(ari2).mean())\n",
    "print(np.array(ari2).std())\n",
    "print(np.array(nmi2).mean())\n",
    "print(np.array(nmi2).std())\n",
    "print(np.array(time2).mean())\n",
    "print(np.array(time2).std())\n",
    "print(\"===\")\n",
    "print(np.array(ari3).mean())\n",
    "print(np.array(ari3).std())\n",
    "print(np.array(nmi3).mean())\n",
    "print(np.array(nmi3).std())\n",
    "print(np.array(time3).mean())\n",
    "print(np.array(time3).std())\n",
    "print(\"===\")\n",
    "print(np.array(ari4).mean())\n",
    "print(np.array(ari4).std())\n",
    "print(np.array(nmi4).mean())\n",
    "print(np.array(nmi4).std())\n",
    "print(np.array(time4).mean())\n",
    "print(np.array(time4).std())\n",
    "print(\"===\")\n",
    "print(np.array(ari4).mean())\n",
    "print(np.array(ari4).std())\n",
    "print(np.array(nmi4).mean())\n",
    "print(np.array(nmi4).std())\n",
    "print(np.array(time4).mean())\n",
    "print(np.array(time4).std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from taucc.taucc import CoClust as CC\n",
    "from tautcc.tautcc import CoClust as TCC\n",
    "from dptaucc.dptaucc import CoClust as DPCC\n",
    "from sklearn.metrics import adjusted_rand_score as ARI \n",
    "from sklearn.metrics import normalized_mutual_info_score as NMI\n",
    "from coclust.coclustering import CoclustInfo as ITCC, CoclustSpecMod as SMCC, CoclustMod as MCC\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tracemalloc\n",
    "from time import time\n",
    "from sklearn.datasets import make_biclusters, make_checkerboard\n",
    "from sklearn.cluster import SpectralCoclustering as SC, SpectralBiclustering as SB\n",
    "\n",
    "\n",
    "B, rlabel, clabel = make_biclusters(shape=(2000,1000), n_clusters=4, random_state=42, noise = 5, minval=1, maxval=10, shuffle=True)\n",
    "#B, rlabel, clabel = make_checkerboard(shape=(2000,1000), n_clusters=(10,5), random_state=42, noise = 1, minval=10, maxval=100, shuffle=True)\n",
    "B= np.array(B.astype(int))\n",
    "B[B<=0]=0\n",
    "row_labels = np.zeros(np.shape(B)[0])\n",
    "col_labels = np.zeros(np.shape(B)[1])\n",
    "rl = np.where(rlabel==True)\n",
    "row_labels[rl[1][:len(row_labels)]] = rl[0][:len(row_labels)]\n",
    "cl = np.where(clabel==True)\n",
    "col_labels[cl[1][:len(col_labels)]] = cl[0][:len(col_labels)]\n",
    "\n",
    "rari = {}\n",
    "rnmi = {}\n",
    "cari = {}\n",
    "cnmi = {}\n",
    "eltime = {}\n",
    "usedmem = {}\n",
    "\n",
    "for model_type in ['cc', 'tcc', 'itcc', 'smcc', 'mcc', 'sc', 'sb']:\n",
    "    rari[model_type] = []\n",
    "    rnmi[model_type] = []\n",
    "    cari[model_type] = []\n",
    "    cnmi[model_type] = []\n",
    "    eltime[model_type] = []\n",
    "    usedmem[model_type] = []\n",
    "    for i in range(20):\n",
    "        print(f'model {model_type} iteration {i}')\n",
    "        if model_type == 'cc':\n",
    "            model = CC(k = 50, l = 50, verbose = False)\n",
    "        elif model_type == 'tcc':\n",
    "            model = TCC(k=[10,10], verbose = False)\n",
    "        elif model_type == 'itcc':\n",
    "            model = ITCC(n_row_clusters=5, n_col_clusters=5)\n",
    "        elif model_type == 'smcc':\n",
    "            model = SMCC(n_clusters=5)\n",
    "        elif model_type == 'mcc':\n",
    "            model = MCC(n_clusters=5)\n",
    "        elif model_type == 'sc':\n",
    "            model = SC(n_clusters=5)\n",
    "        elif model_type == 'sb':\n",
    "            model = SB(n_clusters=5)\n",
    "        tracemalloc.start()\n",
    "        start_time = time()\n",
    "        model.fit(B)\n",
    "        end_time = time()\n",
    "        _, mem = tracemalloc.get_traced_memory()\n",
    "        tracemalloc.stop()\n",
    "        usedmem[model_type].append(mem)\n",
    "        eltime[model_type].append(end_time-start_time)\n",
    "        if model_type == 'tcc':\n",
    "            rari[model_type].append(ARI(row_labels,model.labels_[0]))\n",
    "            cari[model_type].append(ARI(col_labels,model.labels_[1]))\n",
    "            rnmi[model_type].append(NMI(row_labels,model.labels_[0]))\n",
    "            cnmi[model_type].append(NMI(col_labels,model.labels_[1]))\n",
    "        else:\n",
    "            rari[model_type].append(ARI(row_labels,model.row_labels_))\n",
    "            cari[model_type].append(ARI(col_labels,model.column_labels_))\n",
    "            rnmi[model_type].append(NMI(row_labels,model.row_labels_))\n",
    "            cnmi[model_type].append(NMI(col_labels,model.column_labels_))\n",
    "        \n",
    "\n",
    "for model_type in ['cc', 'tcc', 'itcc', 'smcc', 'mcc', 'sc', 'sb']:\n",
    "    print(f'==Results for {model_type} ===')\n",
    "    print(f'used RAM: {np.array(usedmem[model_type]).mean()/(1024*1024):0.2f} +/- {np.array(usedmem[model_type]).std()/(1024*1024):0.2f} MB')\n",
    "    print(f'elapsed time: {np.array(eltime[model_type]).mean():0.4f} +/- {np.array(eltime[model_type]).std():0.4f} sec')\n",
    "    print(f'row ARI: {np.array(rari[model_type]).mean():0.4f} +/- {np.array(rari[model_type]).std():0.4f}')\n",
    "    print(f'col ARI: {np.array(cari[model_type]).mean():0.4f} +/- {np.array(cari[model_type]).std():0.4f}')\n",
    "    print(f'row NMI: {np.array(rnmi[model_type]).mean():0.4f} +/- {np.array(rnmi[model_type]).std():0.4f}')\n",
    "    print(f'col NMI: {np.array(cnmi[model_type]).mean():0.4f} +/- {np.array(cnmi[model_type]).std():0.4f}')\n",
    "    print('')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

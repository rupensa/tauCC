{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialization step for (1000,1000)-siezed input matrix.\n",
      "iteration 0, moving rows, n_clusters: (5, 100), n_moves: 969\n",
      "Values of tau_x: 0.1073 and tau_y: 0.0038, for (5,100)-sized T at iteration: 0 (on rows).\n",
      "iteration 1, moving rows, n_clusters: (5, 100), n_moves: 0\n",
      "Values of tau_x: 0.1073 and tau_y: 0.0038, for (5,100)-sized T at iteration: 0 (on rows).\n",
      "iteration 2, moving columns, n_clusters: (5, 5), n_moves: 971\n",
      "Values of tau_x: 1.0000 and tau_y: 1.0000, for (5,5)-sized T at iteration: 0 (on columns).\n",
      "iteration 3, moving columns, n_clusters: (5, 5), n_moves: 0\n",
      "Values of tau_x: 1.0000 and tau_y: 1.0000, for (5,5)-sized T at iteration: 0 (on columns).\n",
      "iteration 4, moving rows, n_clusters: (5, 5), n_moves: 0\n",
      "Values of tau_x: 1.0000 and tau_y: 1.0000, for (5,5)-sized T at iteration: 1 (on rows).\n",
      "iteration 5, moving columns, n_clusters: (5, 5), n_moves: 0\n",
      "Values of tau_x: 1.0000 and tau_y: 1.0000, for (5,5)-sized T at iteration: 1 (on columns).\n",
      "Final values of tau_x: 1.0000 and tau_y: 1.0000, for (5,5)-sized T.\n",
      "Runtime: 0.2923 seconds.\n",
      "used RAM: 16.83MB\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "taux:  1.0000000000000007\n",
      "tauy:  1.0000000000000007\n",
      "0.2922654151916504\n"
     ]
    }
   ],
   "source": [
    "from taucc.taucc import CoClust as CC\n",
    "from tautcc.tautcc import CoClust as TCC\n",
    "from dptaucc.dptaucc import CoClust as DPCC\n",
    "from sklearn.metrics import adjusted_rand_score as ARI \n",
    "from sklearn.metrics import normalized_mutual_info_score as NMI\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tracemalloc\n",
    "from sklearn.datasets import make_biclusters\n",
    "\n",
    "\n",
    "B, rlabel, clabel = make_biclusters(shape=(1000,1000), n_clusters=5, random_state=42, minval=10, maxval=100, shuffle=True)\n",
    "B= np.array(B.astype(int))\n",
    "row_labels = np.zeros(np.shape(B)[0])\n",
    "col_labels = np.zeros(np.shape(B)[1])\n",
    "rl = np.where(rlabel==True)\n",
    "row_labels[rl[1][:len(row_labels)]] = rl[0][:len(row_labels)]\n",
    "cl = np.where(clabel==True)\n",
    "col_labels[cl[1][:len(col_labels)]] = cl[0][:len(col_labels)]\n",
    "\n",
    "#model = DPCC(eps = 1, n_iterations = 3, n_iter_per_mode = 5, k = 5, l = 5, verbose = True)\n",
    "model = CC(k = 100, l = 100, verbose = True)\n",
    "#model = TCC(k=[100,100], verbose = True)\n",
    "tracemalloc.start()\n",
    "model.fit(B)\n",
    "_, mem = tracemalloc.get_traced_memory()\n",
    "print(f'used RAM: {mem/(1024*1024):0.2f}MB')\n",
    "print(ARI(row_labels,model.row_labels_))\n",
    "print(NMI(row_labels,model.row_labels_))\n",
    "print(ARI(col_labels,model.column_labels_))\n",
    "print(NMI(col_labels,model.column_labels_))\n",
    "#print(model.eps_used)\n",
    "tx, ty = model.compute_taus()\n",
    "t = model.compute_taus()\n",
    "#print(\"taux: \",str(t[0]))\n",
    "#print(\"tauy: \",str(t[1]))\n",
    "print(\"taux: \",str(tx))\n",
    "print(\"tauy: \",str(ty))\n",
    "print(model.execution_time_)\n",
    "tracemalloc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialization step for [1000 1000  100]-sized input matrix.\n",
      "iteration 0, moving mode 0, n_clusters: ([4 5 5]), n_moves: 312\n",
      "Values of tau: [0.00740424 0.00849686 0.00791645], for [4 5 5]-sized T at iteration: 0 (on mode 0).\n",
      "iteration 1, moving mode 0, n_clusters: ([4 5 5]), n_moves: 0\n",
      "Values of tau: [0.00740424 0.00849686 0.00791645], for [4 5 5]-sized T at iteration: 0 (on mode 0).\n",
      "iteration 2, moving mode 1, n_clusters: ([4 4 5]), n_moves: 416\n",
      "Values of tau: [0.02049798 0.02049966 0.02309566], for [4 4 5]-sized T at iteration: 0 (on mode 1).\n",
      "iteration 3, moving mode 1, n_clusters: ([4 4 5]), n_moves: 0\n",
      "Values of tau: [0.02049798 0.02049966 0.02309566], for [4 4 5]-sized T at iteration: 0 (on mode 1).\n",
      "iteration 4, moving mode 2, n_clusters: ([4 4 5]), n_moves: 18\n",
      "Values of tau: [0.02765776 0.02765427 0.03480787], for [4 4 5]-sized T at iteration: 0 (on mode 2).\n",
      "iteration 5, moving mode 2, n_clusters: ([4 4 5]), n_moves: 0\n",
      "Values of tau: [0.02765776 0.02765427 0.03480787], for [4 4 5]-sized T at iteration: 0 (on mode 2).\n",
      "iteration 6, moving mode 0, n_clusters: ([4 4 5]), n_moves: 0\n",
      "Values of tau: [0.02765776 0.02765427 0.03480787], for [4 4 5]-sized T at iteration: 1 (on mode 0).\n",
      "iteration 7, moving mode 1, n_clusters: ([4 4 5]), n_moves: 0\n",
      "Values of tau: [0.02765776 0.02765427 0.03480787], for [4 4 5]-sized T at iteration: 1 (on mode 1).\n",
      "iteration 8, moving mode 2, n_clusters: ([4 4 5]), n_moves: 0\n",
      "Values of tau: [0.02765776 0.02765427 0.03480787], for [4 4 5]-sized T at iteration: 1 (on mode 2).\n",
      "Final values of tau: [0.02765776 0.02765427 0.03480787], for [4 4 5]-sized T.\n",
      "Runtime: 8.3080 seconds.\n",
      "used RAM: 2804.02MB\n",
      "0.7819253438113949\n",
      "0.7819253438113949\n",
      "1.0\n",
      "8.307990789413452\n"
     ]
    }
   ],
   "source": [
    "from taucc.taucc import CoClust as CC\n",
    "from tautcc.tautcc import CoClust as TCC\n",
    "from dptaucc.dptaucc import CoClust as DPCC\n",
    "from sklearn.metrics import adjusted_rand_score as ARI \n",
    "from sklearn.metrics import normalized_mutual_info_score as NMI\n",
    "from sklearn.datasets import make_biclusters\n",
    "from tautcc.CreateMatrix import CreateTensor3\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tracemalloc\n",
    "\n",
    "\n",
    "V, x, y, z = CreateTensor3(nrows = 1000, ncols = 1000, nz = 100, rowclust = 5, colclust = 5, zclust = 5, noise=0.15)\n",
    "\n",
    "model = TCC(k=[5,5,5], verbose=True)\n",
    "tracemalloc.start()\n",
    "model.fit(V)\n",
    "_, mem = tracemalloc.get_traced_memory()\n",
    "print(f'used RAM: {mem/(1024*1024):0.2f}MB')\n",
    "print(ARI(x,model.labels_[0]))\n",
    "print(ARI(y,model.labels_[1]))\n",
    "print(ARI(z,model.labels_[2]))\n",
    "print(model.execution_time_)\n",
    "tracemalloc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from taucc.taucc import CoClust as CC\n",
    "from tautcc.tautcc import CoClust as TCC\n",
    "from dptaucc.dptaucc import CoClust as DPCC\n",
    "from sklearn.metrics import adjusted_rand_score as ARI \n",
    "from sklearn.metrics import normalized_mutual_info_score as NMI\n",
    "from sklearn.datasets import make_biclusters\n",
    "from tautcc.CreateMatrix import CreateTensor3\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tracemalloc\n",
    "\n",
    "dt = pd.read_csv(f'../data/cstr.txt')\n",
    "t = pd.read_csv(f'../data/cstr_target.txt', header = None)\n",
    "target = np.array(t).T[0]\n",
    "\n",
    "\n",
    "n = len(dt.doc.unique())\n",
    "m = len(dt.word.unique())\n",
    "k = len(t[0].unique())\n",
    "T = np.zeros((n,m), dtype = int)\n",
    "\n",
    "\n",
    "for g in dt.iterrows():\n",
    "    T[g[1].doc,g[1].word] = g[1].cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n"
     ]
    }
   ],
   "source": [
    "ari1 = []\n",
    "nmi1 = []\n",
    "time1 = []\n",
    "\n",
    "for i in range(20):\n",
    "    print(i)\n",
    "    model = DPCC(eps = 1., n_iterations = 3, k = 5, l = 5, random_state=None, verbose = False)\n",
    "    model.fit(T)\n",
    "    ari1.append(ARI(target,model.row_labels_))\n",
    "    nmi1.append(NMI(target,model.row_labels_))\n",
    "    time1.append(model.execution_time_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n"
     ]
    }
   ],
   "source": [
    "ari2 = []\n",
    "nmi2 = []\n",
    "time2 = []\n",
    "\n",
    "for i in range(20):\n",
    "    print(i)\n",
    "    model = CC(k = 100, l = 100, initialization='random', verbose = False)\n",
    "    model.fit(T)\n",
    "    ari2.append(ARI(target,model.row_labels_))\n",
    "    nmi2.append(NMI(target,model.row_labels_))\n",
    "    time2.append(model.execution_time_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.646420315684306\n",
      "0.1136671983532591\n",
      "0.6237606230345885\n",
      "0.09796569875281624\n",
      "0.029716432094573975\n",
      "0.023818596798562488\n",
      "===\n",
      "0.6936906430023547\n",
      "0.039709172520825876\n",
      "0.6635784587451481\n",
      "0.040819859046166175\n",
      "0.17503979206085205\n",
      "0.11758415609974694\n"
     ]
    }
   ],
   "source": [
    "print(np.array(ari1).mean())\n",
    "print(np.array(ari1).std())\n",
    "print(np.array(nmi1).mean())\n",
    "print(np.array(nmi1).std())\n",
    "print(np.array(time1).mean())\n",
    "print(np.array(time1).std())\n",
    "print(\"===\")\n",
    "print(np.array(ari2).mean())\n",
    "print(np.array(ari2).std())\n",
    "print(np.array(nmi2).mean())\n",
    "print(np.array(nmi2).std())\n",
    "print(np.array(time2).mean())\n",
    "print(np.array(time2).std())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
